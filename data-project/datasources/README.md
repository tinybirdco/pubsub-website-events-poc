# Data Sources

**Event object feed handling**
* encoded_messages.datasource - Receives incoming *encoded* Pub/Sub messgages. The JSON event objects are encoded in the first column, `message_data`.  
* events_mv.datasource - This is our fundamental `events` table and it is materialized from the `decoded_events` Pipe, which decodes the `message_data` and writes into a `event_data` column contains the decoded JSON. Next, the `JSONExtractString` function is used to extract JSON objects of interest. 
Schema:
```code
`event_id` String,
`event_time` DateTime64(3),
`event` String,
`product` String,
`city` String,
`country` String,
`publish_time` DateTime64(3),
`environment` String,
`latency` Int8,
`location_object` String,
`generator_object` String,
`actor_object` String,
```
**Products dimensional table**
The incoming Pub/Sub feed provides common `product` key/id shared with this product table.   

* products.datasource - A dimensional table containing Product metadata, including `brand`, `category`, `model`, `id` and `price`. For a more interesting dataset, we could add more products and make the generation of product events less uniform. 

**Daily and Hourly Rollups**
* daily_events_mv.datasource - Generated by the `make_hourly_events_mv` Pipe which manages the rollup when new data is ingested into the `events_mv` Data Source. 
* hourly_events_mv.datasource - Generated by the `make_daily_mv` Pipe which manages the rollup when new data is ingested into the `events_mv` Data Source. 
* Note: These Pipes do not JOIN with the `Products` table, so generate just a count of events that are not delineated by Product attributes. 

**Building an hourly rollup with Product details** 
* hourly_events_details_mv.datasource - An updated version of hourly_events_mv.datasource that makes hourly rolls grouped by product. 
